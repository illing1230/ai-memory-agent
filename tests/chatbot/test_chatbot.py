#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ LLM ì§ˆë¬¸ ë‹µë³€í˜• ì±—ë´‡
AI Memory Agent SDKë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ë‚´ìš©ì„ ë©”ëª¨ë¦¬ë¡œ ì „ì†¡
"""

import asyncio
import os
import sys
from typing import Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (tests/chatbot/ì—ì„œ ì‹¤í–‰í•  ë•Œ)
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

# AI Memory Agent SDK ì„í¬íŠ¸
try:
    from ai_memory_agent_sdk import AIMemoryAgentSyncClient, AuthenticationError, APIError, ConnectionError
except ImportError:
    print("AI Memory Agent SDKê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ì„¤ì¹˜: pip install -e ai_memory_agent_sdk")
    sys.exit(1)

# LLM Provider ì„í¬íŠ¸
try:
    from src.shared.providers import get_llm_provider
except ImportError:
    print("LLM Providerë¥¼ ì„í¬íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    sys.exit(1)


class SimpleChatbot:
    """ê°„ë‹¨í•œ LLM ì±—ë´‡"""
    
    def __init__(
        self,
        api_key: str,
        base_url: str = "http://localhost:8000",
        llm_provider: str = "openai",
        agent_id: str = "test",
    ):
        """
        ì±—ë´‡ ì´ˆê¸°í™”
        
        Args:
            api_key: AI Memory Agent API Key
            base_url: AI Memory Agent ì„œë²„ URL
            llm_provider: LLM ì œê³µì (openai, anthropic, ollama)
            agent_id: Agent Instance ID
        """
        self.agent_client = AIMemoryAgentSyncClient(
            api_key=api_key,
            base_url=base_url,
            agent_id=agent_id,
        )
        
        # LLM Provider ì„¤ì •
        os.environ["LLM_PROVIDER"] = llm_provider
        self.llm = get_llm_provider()
        
        self.conversation_history = []
    
    def send_to_memory(self, content: str, data_type: str = "memory"):
        """
        AI Memory Agentë¡œ ë°ì´í„° ì „ì†¡
        
        Args:
            content: ì „ì†¡í•  ë‚´ìš©
            data_type: ë°ì´í„° íƒ€ì… (memory, message, log)
        """
        try:
            result = self.agent_client.send_memory(
                content=content,
                metadata={
                    "source": "test_chatbot",
                    "data_type": data_type,
                }
            )
            print(f"âœ… ë©”ëª¨ë¦¬ ì „ì†¡ ì„±ê³µ: {result['id']}")
        except AuthenticationError as e:
            print(f"âŒ ì¸ì¦ ì˜¤ë¥˜: {e}")
        except APIError as e:
            print(f"âŒ API ì˜¤ë¥˜: {e}")
        except ConnectionError as e:
            print(f"âŒ ì—°ê²° ì˜¤ë¥˜: {e}")
        except Exception as e:
            print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    
    async def chat(self, user_input: str) -> str:
        """
        ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            
        Returns:
            LLM ì‘ë‹µ
        """
        # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        self.conversation_history.append({"role": "user", "content": user_input})
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë©”ëª¨ë¦¬ë¡œ ì „ì†¡
        print(f"\nğŸ“¤ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë©”ëª¨ë¦¬ë¡œ ì „ì†¡ ì¤‘...")
        self.send_to_memory(user_input, "message")
        
        # LLM ì‘ë‹µ ìƒì„±
        print(f"\nğŸ¤– LLM ì‘ë‹µ ìƒì„± ì¤‘...")
        try:
            # ëŒ€í™” ê¸°ë¡ì„ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
            conversation_text = "\n".join([
                f"{msg['role']}: {msg['content']}"
                for msg in self.conversation_history
            ])
            
            response = await self.llm.generate(
                prompt=conversation_text,
                temperature=0.7,
                max_tokens=500,
            )
            assistant_message = response
            
            # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì„ ë©”ëª¨ë¦¬ë¡œ ì „ì†¡
            print(f"\nğŸ“¤ ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì„ ë©”ëª¨ë¦¬ë¡œ ì „ì†¡ ì¤‘...")
            self.send_to_memory(assistant_message, "message")
            
            # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            self.conversation_history.append({"role": "assistant", "content": assistant_message})
            
            return assistant_message
        except Exception as e:
            error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            print(f"âŒ {error_msg}")
            return error_msg
    
    async def extract_memory(self, conversation: str) -> str:
        """
        ëŒ€í™”ì—ì„œ ì¤‘ìš”í•œ ë©”ëª¨ë¦¬ ì¶”ì¶œ
        
        Args:
            conversation: ëŒ€í™” ë‚´ìš©
            
        Returns:
            ì¶”ì¶œëœ ë©”ëª¨ë¦¬
        """
        print(f"\nğŸ§  ëŒ€í™”ì—ì„œ ë©”ëª¨ë¦¬ ì¶”ì¶œ ì¤‘...")
        
        prompt = f"""ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì‚¬ìš©ìì˜ ì¤‘ìš”í•œ ì •ë³´, ì„ í˜¸ë„, ê´€ì‹¬ì‚¬ ë“±ì„ ì¶”ì¶œí•˜ì—¬ ìš”ì•½í•´ì£¼ì„¸ìš”:

ëŒ€í™”:
{conversation}

ì¶”ì¶œëœ ë©”ëª¨ë¦¬:"""
        
        try:
            response = await self.llm.generate(
                prompt=prompt,
                temperature=0.3,
                max_tokens=300,
            )
            
            memory = response.strip()
            
            # ì¶”ì¶œëœ ë©”ëª¨ë¦¬ë¥¼ ì „ì†¡
            print(f"\nğŸ“¤ ì¶”ì¶œëœ ë©”ëª¨ë¦¬ë¥¼ ì „ì†¡ ì¤‘...")
            self.send_to_memory(memory, "memory")
            
            return memory
        except Exception as e:
            print(f"âŒ ë©”ëª¨ë¦¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    async def run(self):
        """ì±—ë´‡ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸ¤– AI Memory Agent í…ŒìŠ¤íŠ¸ ì±—ë´‡")
        print("=" * 60)
        print("\nëª…ë ¹ì–´:")
        print("  /exit  - ì±—ë´‡ ì¢…ë£Œ")
        print("  /clear - ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”")
        print("  /memory - ëŒ€í™”ì—ì„œ ë©”ëª¨ë¦¬ ì¶”ì¶œ")
        print("  /help  - ë„ì›€ë§")
        print("=" * 60)
        
        # ì„œë²„ í—¬ìŠ¤ ì²´í¬
        print("\nğŸ” AI Memory Agent ì„œë²„ ì—°ê²° í™•ì¸ ì¤‘...")
        if self.agent_client.health_check():
            print("âœ… ì„œë²„ ì—°ê²° ì„±ê³µ")
        else:
            print("âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
            print("ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
        
        print("\nğŸ’¬ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")
        
        while True:
            try:
                # ì‚¬ìš©ì ì…ë ¥
                user_input = input("ğŸ‘¤ You: ").strip()
                
                if not user_input:
                    continue
                
                # ëª…ë ¹ì–´ ì²˜ë¦¬
                if user_input.lower() == "/exit":
                    print("\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                elif user_input.lower() == "/clear":
                    self.conversation_history = []
                    print("âœ… ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    continue
                
                elif user_input.lower() == "/memory":
                    if len(self.conversation_history) >= 2:
                        conversation_text = "\n".join([
                            f"{msg['role']}: {msg['content']}"
                            for msg in self.conversation_history[-10:]  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€
                        ])
                        memory = await self.extract_memory(conversation_text)
                        if memory:
                            print(f"\nğŸ“ ì¶”ì¶œëœ ë©”ëª¨ë¦¬:\n{memory}\n")
                    else:
                        print("âŒ ë©”ëª¨ë¦¬ë¥¼ ì¶”ì¶œí•  ëŒ€í™”ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                    continue
                
                elif user_input.lower() == "/help":
                    print("\nëª…ë ¹ì–´:")
                    print("  /exit  - ì±—ë´‡ ì¢…ë£Œ")
                    print("  /clear - ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”")
                    print("  /memory - ëŒ€í™”ì—ì„œ ë©”ëª¨ë¦¬ ì¶”ì¶œ")
                    print("  /help  - ë„ì›€ë§")
                    print()
                    continue
                
                # ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬
                response = await self.chat(user_input)
                print(f"\nğŸ¤– Assistant: {response}\n")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}\n")


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API Key ê°€ì ¸ì˜¤ê¸°
    api_key = os.getenv("AI_MEMORY_AGENT_API_KEY","sk_49ab5d01bc934f818cde6e68a55d7bb7")
    
    if not api_key:
        print("âŒ AI_MEMORY_AGENT_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("\nì‚¬ìš©ë²•:")
        print("  export AI_MEMORY_AGENT_API_KEY='your_api_key_here'")
        print("  python tests/chatbot/test_chatbot.py")
        print("\në˜ëŠ”:")
        print("  AI_MEMORY_AGENT_API_KEY='your_api_key_here' python tests/chatbot/test_chatbot.py")
        sys.exit(1)
    
    # LLM Provider ì„¤ì •
    llm_provider = os.getenv("LLM_PROVIDER", "openai")
    
    # ì±—ë´‡ ì‹¤í–‰
    chatbot = SimpleChatbot(
        api_key=api_key,
        base_url="http://10.244.14.73:8000",
        llm_provider=llm_provider,
    )
    
    await chatbot.run()


if __name__ == "__main__":
    asyncio.run(main())
